
=== 2025-10-23T19:25:40.859960 | GPU 2 | attempt 1 ===
CMD: /home/zhangqi/.conda/envs/env/bin/python /data/zq/evolve/AlgoTune/scripts/gen_solver.py --task clustering_outliers --model-path /data/zq/models/gpt-oss-20b --tasks-root /data/zq/evolve/AlgoTune/AlgoTuneTasks --out-root /data/zq/evolve/AlgoTune/results/chatgptoss-20b --max-new-tokens 1600
[INFO] Task       : clustering_outliers
[INFO] Model Path : /data/zq/models/gpt-oss-20b
[INFO] Desc Path  : /data/zq/evolve/AlgoTune/AlgoTuneTasks/clustering_outliers/description.txt
[INFO] Task Py    : /data/zq/evolve/AlgoTune/AlgoTuneTasks/clustering_outliers/clustering_outliers.py
[INFO] Output Dir : /data/zq/evolve/AlgoTune/results/chatgptoss-20b/clustering_outliers
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]Fetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 11041.89it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s][AFetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 6888.30it/s]
Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:03<00:06,  3.13s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:03,  3.42s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:07<00:03,  3.69s/it]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]Fetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 4810.39it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s][AFetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 8111.24it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 479, in <module>
    main()
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 468, in main
    tok, mdl = load_model(model_path)
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 316, in load_model
    mdl = candidate.from_pretrained(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 774, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/quantizers/quantizer_mxfp4.py", line 248, in create_quantized_param
    load_and_swizzle_mxfp4(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/integrations/mxfp4.py", line 399, in load_and_swizzle_mxfp4
    blocks = blocks.to(target_device).contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 10.44 MiB is free. Process 1375619 has 27.67 GiB memory in use. Including non-PyTorch memory, this process has 11.70 GiB memory in use. Of the allocated memory 11.23 GiB is allocated by PyTorch, and 60.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Expected 'True' or 'False' at index 2 in ConfigTokenizer but got 'true'
Exception raised from toBool at /pytorch/c10/core/AllocatorConfig.h:79 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f3196b03b80 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x65 (0x7f3196a95fbf in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: c10::CachingAllocator::AcceleratorAllocatorConfig::parseExpandableSegments(c10::CachingAllocator::ConfigTokenizer const&, unsigned long) + 0x10d (0x7f3196a9945d in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #3: c10::CachingAllocator::AcceleratorAllocatorConfig::parseArgs(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x44a (0x7f3196a99dca in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #4: <unknown function> + 0x344cf (0x7f3196a9a4cf in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #5: c10::CachingAllocator::AcceleratorAllocatorConfig::instance() + 0x58 (0x7f3196a9a7d8 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0xc7b424 (0x7f31978ad424 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xc7406b (0x7f31978a606b in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0x468a7 (0x7f31f6ac28a7 in /lib/x86_64-linux-gnu/libc.so.6)
frame #9: on_exit + 0 (0x7f31f6ac2a60 in /lib/x86_64-linux-gnu/libc.so.6)
frame #10: __libc_start_main + 0xfa (0x7f31f6aa008a in /lib/x86_64-linux-gnu/libc.so.6)
frame #11: <unknown function> + 0x1c434e (0x55f221fb234e in /home/zhangqi/.conda/envs/env/bin/python)


=== 2025-10-23T19:25:58.703194 | GPU 2 | attempt 2 ===
CMD: /home/zhangqi/.conda/envs/env/bin/python /data/zq/evolve/AlgoTune/scripts/gen_solver.py --task clustering_outliers --model-path /data/zq/models/gpt-oss-20b --tasks-root /data/zq/evolve/AlgoTune/AlgoTuneTasks --out-root /data/zq/evolve/AlgoTune/results/chatgptoss-20b --max-new-tokens 1600
[INFO] Task       : clustering_outliers
[INFO] Model Path : /data/zq/models/gpt-oss-20b
[INFO] Desc Path  : /data/zq/evolve/AlgoTune/AlgoTuneTasks/clustering_outliers/description.txt
[INFO] Task Py    : /data/zq/evolve/AlgoTune/AlgoTuneTasks/clustering_outliers/clustering_outliers.py
[INFO] Output Dir : /data/zq/evolve/AlgoTune/results/chatgptoss-20b/clustering_outliers
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]Fetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 10953.28it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s][AFetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 7858.81it/s]
Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.64s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.49s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:05<00:02,  2.70s/it]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]Fetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 4609.62it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s][AFetching 41 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:00<00:00, 5261.33it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 479, in <module>
    main()
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 468, in main
    tok, mdl = load_model(model_path)
  File "/data/zq/evolve/AlgoTune/scripts/gen_solver.py", line 316, in load_model
    mdl = candidate.from_pretrained(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 774, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device)
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/quantizers/quantizer_mxfp4.py", line 248, in create_quantized_param
    load_and_swizzle_mxfp4(
  File "/home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/transformers/integrations/mxfp4.py", line 399, in load_and_swizzle_mxfp4
    blocks = blocks.to(target_device).contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 10.44 MiB is free. Process 1375619 has 27.67 GiB memory in use. Including non-PyTorch memory, this process has 11.70 GiB memory in use. Of the allocated memory 11.23 GiB is allocated by PyTorch, and 60.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
terminate called after throwing an instance of 'c10::Error'
  what():  Expected 'True' or 'False' at index 2 in ConfigTokenizer but got 'true'
Exception raised from toBool at /pytorch/c10/core/AllocatorConfig.h:79 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fcd03df8b80 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x65 (0x7fcd03d8afbf in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: c10::CachingAllocator::AcceleratorAllocatorConfig::parseExpandableSegments(c10::CachingAllocator::ConfigTokenizer const&, unsigned long) + 0x10d (0x7fcd03d8e45d in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #3: c10::CachingAllocator::AcceleratorAllocatorConfig::parseArgs(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x44a (0x7fcd03d8edca in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #4: <unknown function> + 0x344cf (0x7fcd03d8f4cf in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #5: c10::CachingAllocator::AcceleratorAllocatorConfig::instance() + 0x58 (0x7fcd03d8f7d8 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0xc7b424 (0x7fcd04ba2424 in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xc7406b (0x7fcd04b9b06b in /home/zhangqi/.conda/envs/env/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #8: <unknown function> + 0x468a7 (0x7fcd63db78a7 in /lib/x86_64-linux-gnu/libc.so.6)
frame #9: on_exit + 0 (0x7fcd63db7a60 in /lib/x86_64-linux-gnu/libc.so.6)
frame #10: __libc_start_main + 0xfa (0x7fcd63d9508a in /lib/x86_64-linux-gnu/libc.so.6)
frame #11: <unknown function> + 0x1c434e (0x55c83f14e34e in /home/zhangqi/.conda/envs/env/bin/python)

